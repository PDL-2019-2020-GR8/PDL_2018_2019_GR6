Dataset name,Brief description,Preprocessing,Instances,Format,Default task,Created (updated),Reference,Creator
FERET (facial recognition technology),11338 images of 1199 individuals in different positions and at different times.,None.,11.338,Images,Classification  face recognition,2003,[6][7],United States Department of Defense
Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS),7.356 video and audio recordings of 24 professional actors. 8 emotions each at two intensities.,Files labelled with expression. Perceptual validation ratings provided by 319 raters.,7.356,Video  sound files,Classification  face recognition  voice recognition,2018,[8][9],S.R. Livingstone and F.A. Russo
SCFace,Color images of faces at various angles.,Location of facial features extracted. Coordinates of features given.,4.160,Images  text,Classification  face recognition,2011,[10][11],M. Grgic et al.
Yale Face Database,Faces of 15 individuals in 11 different expressions.,Labels of expressions.,165,Images,Face recognition,1997,[12][13],J. Yang et al.
Cohn-Kanade AU-Coded Expression Database,Large database of images with labels for expressions.,Tracking of certain facial features.,500+ sequences,Images  text,Facial expression analysis,2000,[14][15],T. Kanade et al.
JAFFE Facial Expression Database,213 images of 7 facial expressions (6 basic facial expressions + 1 neutral) posed by 10 Japanese female models.,Images are cropped to the facial region. Includes semantic ratings data on emotion labels.,213,Images  text,Facial expression cognition,1998,[16][17],Lyons  Kamachi  Gyoba
FaceScrub,Images of public figures scrubbed from image searching.,Name and m/f annotation.,107.818,Images  text,Face recognition,2014,[18][19],H. Ng et al.
BioID Face Database,Images of faces with eye positions marked.,Manually set eye positions.,1521,Images  text,Face recognition,2001,[20][21],BioID
Skin Segmentation Dataset,Randomly sampled color values from face images.,B  G  R  values extracted.,245.057,Text,Segmentation  classification,2012,[22][23],R. Bhatt.
Bosphorus,3D Face image database.,34 action units and 6 expressions labeled; 24 facial landmarks labeled.,4652,Images  text,Face recognition  classification,2008,[24][25],A Savran et al.
UOY 3D-Face,neutral face  5 expressions: anger  happiness  sadness  eyes closed  eyebrows raised.,labeling.,5250,Images  text,Face recognition  classification,2004,[26][27],University of York
CASIA,Expressions: Anger  smile  laugh  surprise  closed eyes.,None.,4624,Images  text,Face recognition  classification,2007,[28][29],Institute of Automation  Chinese Academy of Sciences
CASIA,Expressions: Anger Disgust Fear Happiness Sadness Surprise,None.,480,Annotated Visible Spectrum and Near Infrared Video captures at 25 frames per second,Face recognition  classification,2011,[30],Zhao  G. et al.
BU-3DFE,neutral face  and 6 expressions: anger  happiness  sadness  surprise  disgust  fear (4 levels). 3D images extracted.,None.,2500,Images  text,Facial expression recognition  classification,2006,[31],Binghamton University
Face Recognition Grand Challenge Dataset,Up to 22 samples for each subject. Expressions: anger  happiness  sadness  surprise  disgust  puffy. 3D Data.,None.,4007,Images  text,Face recognition  classification,2004,[32][33],National Institute of Standards and Technology
Gavabdb,Up to 61 samples for each subject. Expressions neutral face  smile  frontal accentuated laugh  frontal random gesture. 3D images.,None.,549,Images  text,Face recognition  classification,2008,[34][35],King Juan Carlos University
3D-RMA,Up to 100 subjects  expressions mostly neutral. Several poses as well.,None.,9971,Images  text,Face recognition  classification,2004,[36][37],Royal Military Academy (Belgium)
SoF,112 persons (66 males and 46 females) wear glasses under different illumination conditions.,A set of synthetic filters (blur  occlusions  noise  and posterization ) with different level of difficulty.,42.592 (2.662 original image × 16 synthetic image),Images  Mat file,Gender classification  face detection  face recognition  age estimation  and glasses detection,2017,[38][39],Afifi  M. et al.
IMDB-WIKI,IMDB and Wikipedia face images with gender and age labels.,None,523.051,Images,Gender classification  face detection  face recognition  age estimation,2015,[40],R. Rothe  R. Timofte  L. V. Gool
Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
TV Human Interaction Dataset,Videos from 20 different TV shows for prediction social actions: handshake  high five  hug  kiss and none.,None.,6.766 video clips,video clips,Action prediction,2013,[41],Patron-Perez  A. et al.
Berkeley Multimodal Human Action Database (MHAD),Recordings of a single person performing 12 actions,MoCap pre-processing,660 action samples,8 PhaseSpace Motion Capture  2 Stereo Cameras  4 Quad Cameras  6 accelerometers  4 microphones,Action classification,2013,[42],Ofli  F. et al.
THUMOS Dataset,Large video dataset for action classification.,Actions classified and labeled.,45M frames of video,Video  images  text,Classification  action detection,2013,[43][44],Y. Jiang et al.
MEXAction2,Video dataset for action localization and spotting,Actions classified and labeled.,1000,Video,Action detection,2014,[45],Stoian et al.
Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
Visual Genome,Images and their description,[empty],108.000,images  text,Image captioning,2016,[46],R. Krishna et al.
Berkeley 3-D Object Dataset,849 images taken in 75 different scenes. About 50 different object classes are labeled.,Object bounding boxes and labeling.,849,labeled images  text,Object recognition,2014,[47][48],A. Janoch et al.
Berkeley Segmentation Data Set and Benchmarks 500 (BSDS500),500 natural images  explicitly separated into disjoint train  validation and test subsets + benchmarking code. Based on BSDS300.,Each image segmented by five different subjects on average.,500,Segmented images,Contour detection and hierarchical image segmentation,2011,[49],University of California  Berkeley
Microsoft Common Objects in Context (COCO),complex everyday scenes of common objects in their natural context.,Object highlighting  labeling  and classification into 91 object types.,2.500.000,Labeled images  text,Object recognition,2015,[50][51],T. Lin et al.
SUN Database,Very large scene and object recognition database.,Places and objects are labeled. Objects are segmented.,131.067,Images  text,Object recognition  scene recognition,2014,[52][53],J. Xiao et al.
ImageNet,Labeled object image database  used in the ImageNet Large Scale Visual Recognition Challenge,Labeled objects  bounding boxes  descriptive words  SIFT features,14.197.122,Images  text,Object recognition  scene recognition,2009 (2014),[54][55][56],J. Deng et al.
Open Images,A Large set of images listed as having CC BY 2.0 license with image-level labels and bounding boxes spanning thousands of classes.,Image-level labels  Bounding boxes,9.178.275,Images  text,Classification  Object recognition,2017,[57],[empty]
TV News Channel Commercial Detection Dataset,TV commercials and news broadcasts.,Audio and video features extracted from still images.,129.685,Text,Clustering  classification,2015,[58][59],P. Guha et al.
Statlog (Image Segmentation) Dataset,The instances were drawn randomly from a database of 7 outdoor images and hand-segmented to create a classification for every pixel.,Many features calculated.,2310,Text,Classification,1990,[60],University of Massachusetts
Caltech 101,Pictures of objects.,Detailed object outlines marked.,9146,Images,Classification  object recognition.,2003,[61][62],F. Li et al.
Caltech-256,Large dataset of images for object classification.,Images categorized and hand-sorted.,30.607,Images  Text,Classification  object detection,2007,[63][64],G. Griffin et al.
SIFT10M Dataset,SIFT features of Caltech-256 dataset.,Extensive SIFT feature extraction.,11.164.866,Text,Classification  object detection,2016,[65],X. Fu et al.
LabelMe,Annotated pictures of scenes.,Objects outlined.,187.240,Images  text,Classification  object detection,2005,[66],MIT Computer Science and Artificial Intelligence Laboratory
Cityscapes Dataset,Stereo video sequences recorded in street scenes  with pixel-level annotations. Metadata also included.,Pixel-level segmentation and labeling,25.000,Images  text,Classification  object detection,2016,[67],Daimler AG et al.
PASCAL VOC Dataset,Large number of images for classification tasks.,Labeling  bounding box included,500.000,Images  text,Classification  object detection,2010,[68][69],M. Everingham et al.
CIFAR-10 Dataset,Many small  low-resolution  images of 10 classes of objects.,Classes labelled  training set splits created.,60.000,Images,Classification,2009,[55][70],A. Krizhevsky et al.
CIFAR-100 Dataset,Like CIFAR-10  above  but 100 classes of objects are given.,Classes labelled  training set splits created.,60.000,Images,Classification,2009,[55][70],A. Krizhevsky et al.
CINIC-10 Dataset,A unified contribution of CIFAR-10 and Imagenet with 10 classes  and 3 splits. Larger than CIFAR-10.,Classes labelled  training  validation  test set splits created.,270.000,Images,Classification,2018,[71],Luke N. Darlow  Elliot J. Crowley  Antreas Antoniou  Amos J. Storkey
Fashion-MNIST,A MNIST-like fashion product database,Classes labelled  training set splits created.,60.000,Images,Classification,2017,[72],Zalando SE
notMNIST,Some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes  with letters A-J taken from different fonts.,Classes labelled  training set splits created.,500.000,Images,Classification,2011,[73],Yaroslav Bulatov
German Traffic Sign Detection Benchmark Dataset,Images from vehicles of traffic signs on German roads. These signs comply with UN standards and therefore are the same as in other countries.,Signs manually labeled,900,Images,Classification,2013,[74][75],S Houben et al.
KITTI Vision Benchmark Dataset,Autonomous vehicles driving through a mid-size city captured images of various areas using cameras and laser scanners.,Many benchmarks extracted from data.,>100 GB of data,Images  text,Classification  object detection,2012,[76][77],A Geiger et al.
Linnaeus 5 dataset,Images of 5 classes of objects.,Classes labelled  training set splits created.,8000,Images,Classification,2017,[78],Chaladze & Kalatozishvili
FieldSAFE,Multi-modal dataset for obstacle detection in agriculture including stereo camera  thermal camera  web camera  360-degree camera  lidar  radar  and precise localization.,Classes labelled geographically.,>400 GB of data,Images and 3D point clouds,Classification  object detection  object localization,2017,[79],M. Kragh et al.
11K Hands,11.076 hand images (1600 x 1200 pixels) of 190 subjects  of varying ages between 18 – 75 years old  for gender recognition and biometric identification.,None,11.076 hand images,Images and (.mat  .txt  and .csv) label files,Gender recognition and biometric identification,2017,[80],M Afifi
CORe50,Specifically designed for Continuous/Lifelong Learning and Object Recognition  is a collection of more than 500 videos (30fps) of 50 domestic objects belonging to 10 different categories.,Classes labelled  training set splits created based on a 3-way  multi-runs benchmark.,164.866 RBG-D images,images (.png or .pkl) and (.pkl  .txt  .tsv) label files,Classification  Object recognition,2017,[81],V. Lomonaco and D. Maltoni
THz and thermal video data set,This multispectral data set includes terahertz  thermal  visual  near infrared  and three-dimensional videos of objects hidden under people's clothes.,3D lookup tables are provided that allow you to project images onto 3D point clouds.,More than 20 videos. The duration of each video is about 85 seconds (about 345 frames).,AP2J,Experiments with hidden object detection,2019,[82][83],Alexei A. Morozov and Olga S. Sushkova
Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
Artificial Characters Dataset,Artificially generated data describing the structure of 10 capital English letters.,Coordinates of lines drawn given as integers. Various other features.,6000,Text,Handwriting recognition  classification,1992,[84],H. Guvenir et al.
Letter Dataset,Upper case printed letters.,17 features are extracted from all images.,20.000,Text,OCR  classification,1991,[85][86],D. Slate et al.
Character Trajectories Dataset,Labeled samples of pen tip trajectories for people writing simple characters.,3-dimensional pen tip velocity trajectory matrix for each sample,2858,Text,Handwriting recognition  classification,2008,[87][88],B. Williams
Chars74K Dataset,Character recognition in natural images of symbols used in both English and Kannada,[empty],74.107,[empty],Character recognition  handwriting recognition  OCR  classification,2009,[89],T. de Campos
UJI Pen Characters Dataset,Isolated handwritten characters,Coordinates of pen position as characters were written given.,11.640,Text,Handwriting recognition  classification,2009,[90][91],F. Prat et al.
Gisette Dataset,Handwriting samples from the often-confused 4 and 9 characters.,Features extracted from images  split into train/test  handwriting images size-normalized.,13.500,Images  text,Handwriting recognition  classification,2003,[92],Yann LeCun et al.
Omniglot dataset,1623 different handwritten characters from 50 different alphabetss.,Hand-labeled.,38.300,Images  text  strokes,Classification  one-shot learning,2015,[93][94],American Association for the Advancement of Science
MNIST database,Database of handwritten digits.,Hand-labeled.,60.000,Images  text,Classification,1998,[95][96],National Institute of Standards and Technology
Optical Recognition of Handwritten Digits Dataset,Normalized bitmaps of handwritten data.,Size normalized and mapped to bitmaps.,5620,Images  text,Handwriting recognition  classification,1998,[97],E. Alpaydin et al.
Pen-Based Recognition of Handwritten Digits Dataset,Handwritten digits on electronic pen-tablet.,Feature vectors extracted to be uniformly spaced.,10.992,Images  text,Handwriting recognition  classification,1998,[98][99],E. Alpaydin et al.
Semeion Handwritten Digit Dataset,Handwritten digits from 80 people.,All handwritten digits have been normalized for size and mapped to the same grid.,1593,Images  text,Handwriting recognition  classification,2008,[100],T. Srl
HASYv2,Handwritten mathematical symbols,All symbols are centered and of size 32px x 32px.,168233,Images  text,Classification,2017,[101],Martin Thoma
Noisy Handwritten Bangla Dataset,Includes Handwritten Numeral Dataset (10 classes) and Basic Character Dataset (50 classes)  each dataset has three types of noise: white gaussian  motion blur  and reduced contrast.,All images are centered and of size 32x32.,Numeral Dataset: 23330  Character Dataset: 76000,Images  text,Handwriting recognition  classification,2017,[102],M. Karki et al.
Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
Aerial Image Segmentation Dataset,80 high-resolution aerial images with spatial resolution ranging from 0.3 to 1.0.,Images manually segmented.,80,Images,Aerial Classification  object detection,2013,[103][104],J. Yuan et al.
KIT AIS Data Set,Multiple labeled training and evaluation datasets of aerial images of crowds.,Images manually labeled to show paths of individuals through crowds.,~ 150,Images with paths,People tracking  aerial tracking,2012,[105][106],M. Butenuth et al.
Wilt Dataset,Remote sensing data of diseased trees and other land cover.,Various features extracted.,4899,Images,Classification  aerial object detection,2014,[107][108],B. Johnson
Forest Type Mapping Dataset,Satellite imagery of forests in Japan.,Image wavelength bands extracted.,326,Text,Classification,2015,[109][110],B. Johnson
Overhead Imagery Research Data Set,Annotated overhead imagery. Images with multiple objects.,Over 30 annotations and over 60 statistics that describe the target within the context of the image.,1000,Images  text,Classification,2009,[111][112],F. Tanner et al.
SpaceNet,SpaceNet is a corpus of commercial satellite imagery and labeled training data.,GeoTiff and GeoJSON files containing building footprints.,>17533,Images,Classification  Object Identification,2017,[113][114][115],DigitalGlobe  Inc.
UC Merced Land Use Dataset,These images were manually extracted from large images from the USGS National Map Urban Area Imagery collection for various urban areas around the US.,This is a 21 class land use image dataset meant for research purposes. There are 100 images for each class.,2.100,Image chips of 256x256  30 cm (1 foot) GSD,Land cover classification,2010,[116],Yi Yang and Shawn Newsam
SAT-4 Airborne Dataset,Images were extracted from the National Agriculture Imagery Program (NAIP) dataset.,SAT-4 has four broad land cover classes  includes barren land  trees  grassland and a class that consists of all land cover classes other than the above three.,500.000,Images,Classification,2015,[117],S. Basu et al.
SAT-6 Airborne Dataset,Images were extracted from the National Agriculture Imagery Program (NAIP) dataset.,SAT-6 has six broad land cover classes  includes barren land  trees  grassland  roads  buildings and water bodies.,405.000,Images,Classification,2015,[117],S. Basu et al.
Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
Density functional theory quantum simulations of graphene,Labelled images of raw input to a simulation of graphene,Raw data (in HDF5 format) and output labels from density functional theory quantum simulation,60744 test and 501473 and training files,Labeled images,Regression,2019,[118],K. Mills & I. Tamblyn
Quantum simulations of an electron in a two dimensional potential well,Labelled images of raw input to a simulation of 2d Quantum mechanics,Raw data (in HDF5 format) and output labels from quantum simulation,1.3 million images,Labeled images,Regression,2017,[119],K. Mills  M.A. Spanner  & I. Tamblyn
MPII Cooking Activities Dataset,Videos and images of various cooking activities.,Activity paths and directions  labels  fine-grained motion labeling  activity class  still image extraction and labeling.,881.755 frames,Labeled video  images  text,Classification,2012,[120][121],M. Rohrbach et al.
FAMOS Dataset,5.000 unique microstructures  all samples have been acquired 3 times with two different cameras.,Original PNG files  sorted per camera and then per acquisition. MATLAB datafiles with one 16384 times 5000 matrix per camera per acquisition.,30.000,Images and .mat files,Authentication,2012,[122],S. Voloshynovskiy  et al.
PharmaPack Dataset,1.000 unique classes with 54 images per class.,Class labeling  many local descriptors  like SIFT and aKaZE  and local feature agreators  like Fisher Vector (FV).,54.000,Images and .mat files,Fine-grain classification,2017,[123],O. Taran and S. Rezaeifar  et al.
Stanford Dogs Dataset,Images of 120 breeds of dogs from around the world.,Train/test splits and ImageNet annotations provided.,20.580,Images  text,Fine-grain classification,2011,[124][125],A. Khosla et al.
The Oxford-IIIT Pet Dataset,37 categories of pets with roughly 200 images of each.,Breed labeled  tight bounding box  foreground-background segmentation.,~ 7.400,Images  text,Classification  object detection,2012,[125][126],O. Parkhi et al.
Corel Image Features Data Set,Database of images with features extracted.,Many features including color histogram  co-occurrence texture  and colormoments ,68.040,Text,Classification  object detection,1999,[127][128],M. Ortega-Bindenberger et al.
Online Video Characteristics and Transcoding Time Dataset.,Transcoding times for various different videos and video properties.,Video features given.,168.286,Text,Regression,2015,[129],T. Deneke et al.
Microsoft Sequential Image Narrative Dataset (SIND),Dataset for sequential vision-to-language,Descriptive caption and storytelling given for each photo  and photos are arranged in sequences,81.743,Images  text,Visual storytelling,2016,[130],Microsoft Research
Caltech-UCSD Birds-200-2011 Dataset,Large dataset of images of birds.,Part locations for birds  bounding boxes  312 binary attributes given,11.788,Images  text,Classification,2011,[131][132],C. Wah et al.
YouTube-8M,Large and diverse labeled video dataset,YouTube video IDs and associated labels from a diverse vocabulary of 4800 visual entities,8 million,Video  text,Video classification,2016,[133][134],S. Abu-El-Haija et al.
YFCC100M,Large and diverse labeled image and video dataset,Flickr Videos and Images and associated description  titles  tags  and other metadata (such as EXIF and geotags),100 million,Video  Image  Text,Video and Image classification,2016,[135][136],B. Thomee et al.
Discrete LIRIS-ACCEDE,Short videos annotated for valence and arousal.,Valence and arousal labels.,9800,Video,Video emotion elicitation detection,2015,[137],Y. Baveye et al.
Continuous LIRIS-ACCEDE,Long videos annotated for valence and arousal while also collecting Galvanic Skin Response.,Valence and arousal labels.,30,Video,Video emotion elicitation detection,2015,[138],Y. Baveye et al.
MediaEval LIRIS-ACCEDE,Extension of Discrete LIRIS-ACCEDE including annotations for violence levels of the films.,Violence  valence and arousal labels.,10900,Video,Video emotion elicitation detection,2015,[139],Y. Baveye et al.
Leeds Sports Pose,Articulated human pose annotations in 2000 natural sports images from Flickr.,Rough crop around single person of interest with 14 joint labels,2000,Images plus .mat file labels,Human pose estimation,2010,[140],S. Johnson and M. Everingham
Leeds Sports Pose Extended Training,Articulated human pose annotations in 10.000 natural sports images from Flickr.,14 joint labels via crowdsourcing,10000,Images plus .mat file labels,Human pose estimation,2011,[141],S. Johnson and M. Everingham
MCQ Dataset,6 different real multiple choice-based exams (735 answer sheets and 33.540 answer boxes) to evaluate computer vision techniques and systems developed for multiple choice test assessment systems.,None,735 answer sheets and 33.540 answer boxes,Images and .mat file labels,Development of multiple choice test assessment systems,2017,[142][143],Afifi  M. et al.
Surveillance Videos,Real surveillance videos cover a large surveillance time (7 days with 24 hours each).,None,19 surveillance videos (7 days with 24 hours each).,Videos,Data compression,2016,[144],Taj-Eddin  I. A. T. F. et al.
LILA BC,Labeled Information Library of Alexandria: Biology and Conservation. Labeled images that support machine learning research around ecology and environmental science.,None,~10M images,Images,Classification,2019,[145],LILA working group
Can We See Photosynthesis?,32 videos for eight live and eight dead leaves recorded under both DC and AC lighting conditions.,None,32 videos,Videos,Liveness detection of plants,2017,[146],Taj-Eddin  I. A. T. F. et al.
Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
Amazon reviews,US product reviews from Amazon.com.,None.,~ 82M,Text,Classification  sentiment analysis,2015,[147],McAuley et al.
OpinRank Review Dataset,Reviews of cars and hotels from Edmunds.com and TripAdvisor respectively.,None.,42.230 / ~259.000 respectively,Text,Sentiment analysis  clustering,2011,[148][149],K. Ganesan et al.
MovieLens,22.000.000 ratings and 580.000 tags applied to 33.000 movies by 240.000 users.,None.,~ 22M,Text,Regression  clustering  classification,2016,[150],GroupLens Research
Yahoo! Music User Ratings of Musical Artists,Over 10M ratings of artists by Yahoo users.,None described.,~ 10M,Text,Clustering  regression,2004,[151][152],Yahoo!
Car Evaluation Data Set,Car properties and their overall acceptability.,Six categorical features given.,1728,Text,Classification,1997,[153][154],M. Bohanec
YouTube Comedy Slam Preference Dataset,User vote data for pairs of videos shown on YouTube. Users voted on funnier videos.,Video metadata given.,1.138.562,Text,Classification,2012,[155][156],Google
Skytrax User Reviews Dataset,User reviews of airlines  airports  seats  and lounges from Skytrax.,Ratings are fine-grain and include many aspects of airport experience.,41396,Text,Classification  regression,2015,[157],Q. Nguyen
Teaching Assistant Evaluation Dataset,Teaching assistant reviews.,Features of each instance such as class  class size  and instructor are given.,151,Text,Classification,1997,[158][159],W. Loh et al.
Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
NYSK Dataset,English news articles about the case relating to allegations of sexual assault against the former IMF director Dominique Strauss-Kahn.,Filtered and presented in XML format.,10.421,XML  text,Sentiment analysis  topic extraction,2013,[160],Dermouche  M. et al.
The Reuters Corpus Volume 1,Large corpus of Reuters news stories in English.,Fine-grain categorization and topic codes.,810.000,Text,Classification  clustering  summarization,2002,[161],Reuters
The Reuters Corpus Volume 2,Large corpus of Reuters news stories in multiple languages.,Fine-grain categorization and topic codes.,487.000,Text,Classification  clustering  summarization,2005,[162],Reuters
Thomson Reuters Text Research Collection,Large corpus of news stories.,Details not described.,1.800.370,Text,Classification  clustering  summarization,2009,[163],T. Rose et al.
Saudi Newspapers Corpus,31.030 Arabic newspaper articles.,Metadata extracted.,31.030,JSON,Summarization  clustering,2015,[164],M. Alhagri
RE3D (Relationship and Entity Extraction Evaluation Dataset),Entity and Relation marked data from various news and government sources. Sponsored by Dstl,Filtered  categorisation using Baleen types,not known,JSON,Classification  Entity and Relation recognition,2017,[165],Dstl
Examiner Pseudo-News Corpus,Clickbait  spam  crowd-sourced headlines from 2010 to 2015,Publish date and headlines,3.089.781,CSV,Clustering  Events  Sentiment,2017,[166],R. Kulkarni
ABC Australia News Corpus,Entire news corpus of ABC Australia from 2003 to 2017,Publish date and headlines,1.103.664,CSV,Clustering  Events  Sentiment,2017,[167],R. Kulkarni
Worldwide News - Aggregate of 20K Feeds,One week snapshot of all online headlines in 20+ languages,Publish time  URL and headlines,1.398.431,CSV,Clustering  Events  Language Detection,2017,[168],R. Kulkarni
Reuters News Wire Headline,11 Years of timestamped events published on the news-wire,Publish time  Headline Text,16.121.310,CSV,NLP  Computational Linguistics  Events,2018,[169],R. Kulkarni
The Irish Times The Irish Times IRS,23 Years of Events From Ireland,Publish time  Headline Text,1.425.460,CSV,NLP  Computational Linguistics  Events,2018,[170],R. Kulkarni
News Headlines Dataset for Sarcasm Detection,High quality dataset with Sarcastic and Non-sarcastic news headlines.,Clean  normalized text,26.709,JSON,NLP  Classification  Linguistics,2018,[171],Rishabh Misra
Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
Enron Email Dataset,Emails from employees at Enron organized into folders.,Attachments removed  invalid email addresses converted to user@enron.com or no_address@enron.com.,~ 500.000,Text,Network analysis  sentiment analysis,2004 (2015),[172][173],Klimt  B. and Y. Yang
Ling-Spam Dataset,Corpus containing both legitimate and spam emails.,Four version of the corpus involving whether or not a lemmatiser or stop-list was enabled.,[empty],Text,Classification,2000,[174][175],Androutsopoulos  J. et al.
SMS Spam Collection Dataset,Collected SMS spam messages.,None.,5.574,Text,Classification,2011,[176][177],T. Almeida et al.
Twenty Newsgroups Dataset,Messages from 20 different newsgroups.,None.,20.000,Text,Natural language processing,1999,[178],T. Mitchell et al.
Spambase Dataset,Spam emails.,Many text features extracted.,4.601,Text,Spam detection  classification,1999,[179],M. Hopkins et al.
Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
MovieTweetings,Movie rating dataset based on public and well-structured tweets,[empty],~710.000,Text,Classification  regression,2018,[180],S. Dooms
Twitter100k,Pairs of images and tweets,[empty],100.000,Text and Images,Cross-media retrieval,2017,[181][182],Y. Hu  et al.
Sentiment140,Tweet data from 2009 including original text  time stamp  user and sentiment.,Classified using distant supervision from presence of emoticon in tweet.,1.578.627,Tweets  comma  separated values,Sentiment analysis,2009,[183][184],A. Go et al.
ASU Twitter Dataset,Twitter network data  not actual tweets. Shows connections between a large number of users.,None.,11.316.811 users  85.331.846 connections,Text,Clustering  graph analysis,2009,[185][186],R. Zafarani et al.
SNAP Social Circles: Twitter Database,Large Twitter network data.,Node features  circles  and ego networks.,1.768.149,Text,Clustering  graph analysis,2012,[187][188],J. McAuley et al.
Twitter Dataset for Arabic Sentiment Analysis,Arabic tweets.,Samples hand-labeled as positive or negative.,2000,Text,Classification,2014,[189][190],N. Abdulla
Buzz in Social Media Dataset,Data from Twitter and Tom's Hardware. This dataset focuses on specific buzz topics being discussed on those sites.,Data is windowed so that the user can attempt to predict the events leading up to social media buzz.,140.000,Text,Regression  Classification,2013,[191][192],F. Kawala et al.
Paraphrase and Semantic Similarity in Twitter (PIT),This dataset focuses on whether tweets have (almost) same meaning/information or not. Manually labeled.,tokenization  part-of-speech and named entity tagging,18.762,Text,Regression  Classification,2015,[193][194],Xu et al.
Geoparse Twitter benchmark dataset,This dataset contains tweets during different news events in different countries. Manually labeled location mentions.,location annotations added to JSON metadata,6.386,Tweets  JSON,Classification  Information Extraction,2014,[195][196],S.E. Middleton et al.
